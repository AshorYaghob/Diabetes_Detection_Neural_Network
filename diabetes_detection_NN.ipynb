{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8y3ytOzbTGR9KbqWDbuqq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshorYaghob/Diabetes_Detection_Neural_Network/blob/main/diabetes_detection_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load In Dataset\n",
        "We want to load in the dataset and analyze the data.\n",
        "This includes:\n",
        "1. checking for nulls\n",
        "\n",
        "2. Filling in Nulls\n",
        "\n",
        "3. Checking the datatypes\n",
        "\n",
        "4. Encoding Categorical Features\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/abdelazizsami/early-stage-diabetes-risk-prediction"
      ],
      "metadata": {
        "id": "WczKiFlTOEDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVbDL2WGJr-s",
        "outputId": "382524b4-471f-45d7-92a8-4a549466ccea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age                   0\n",
            "Gender                0\n",
            "Polyuria              0\n",
            "Polydipsia            0\n",
            "sudden weight loss    0\n",
            "weakness              0\n",
            "Polyphagia            0\n",
            "Genital thrush        0\n",
            "visual blurring       0\n",
            "Itching               0\n",
            "Irritability          0\n",
            "delayed healing       0\n",
            "partial paresis       0\n",
            "muscle stiffness      0\n",
            "Alopecia              0\n",
            "Obesity               0\n",
            "class                 0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('diabetes_data_upload.csv', sep=',')\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "df.replace(' ', np.nan, inplace=True)\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "J2b_3pUZN77n",
        "outputId": "801756dd-a971-4a76-a183-b7bab43941cd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                    int64\n",
              "Gender                object\n",
              "Polyuria              object\n",
              "Polydipsia            object\n",
              "sudden weight loss    object\n",
              "weakness              object\n",
              "Polyphagia            object\n",
              "Genital thrush        object\n",
              "visual blurring       object\n",
              "Itching               object\n",
              "Irritability          object\n",
              "delayed healing       object\n",
              "partial paresis       object\n",
              "muscle stiffness      object\n",
              "Alopecia              object\n",
              "Obesity               object\n",
              "class                 object\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Polyuria</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Polydipsia</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sudden weight loss</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weakness</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Polyphagia</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Genital thrush</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>visual blurring</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Itching</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Irritability</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delayed healing</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>partial paresis</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>muscle stiffness</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alopecia</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Obesity</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# No Apparant Irrelevant attributes\n",
        "# Keeping code incase someone wants to play around with it\n",
        "irrelevant_attributes = []\n",
        "df.drop(irrelevant_attributes, axis=1, inplace=True)\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlxkamWQOiCR",
        "outputId": "07dd5711-2954-44d2-f962-5cb7eda154dd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age                   0\n",
            "Gender                0\n",
            "Polyuria              0\n",
            "Polydipsia            0\n",
            "sudden weight loss    0\n",
            "weakness              0\n",
            "Polyphagia            0\n",
            "Genital thrush        0\n",
            "visual blurring       0\n",
            "Itching               0\n",
            "Irritability          0\n",
            "delayed healing       0\n",
            "partial paresis       0\n",
            "muscle stiffness      0\n",
            "Alopecia              0\n",
            "Obesity               0\n",
            "class                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
        "print(categorical_features)\n",
        "numerical_features = ['Age']\n",
        "print(numerical_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSI7Uuc6PFpP",
        "outputId": "e6160f31-fda7-4a37-b902-062871676945"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Gender', 'Polyuria', 'Polydipsia', 'sudden weight loss', 'weakness', 'Polyphagia', 'Genital thrush', 'visual blurring', 'Itching', 'Irritability', 'delayed healing', 'partial paresis', 'muscle stiffness', 'Alopecia', 'Obesity', 'class']\n",
            "['Age']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "df_encoded = df.copy()\n",
        "# Make sure the encoder reurns a numpy array and not a matrix, also drop extra category to avoid redundancy\n",
        "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "\n",
        "for col in categorical_features:\n",
        "    # Encode entire column. transformed_data is the new column(s) containing the encoded data\n",
        "    transformed_data = encoder.fit_transform(df_encoded[[col]])\n",
        "    # encoder.get_feature_names_out([col]) generates the column names for the encoded df\n",
        "    # Then it convertes transformed_data into a dataframe with those corresponding column names\n",
        "    encoded_df = pd.DataFrame(transformed_data, columns=encoder.get_feature_names_out([col]))\n",
        "    # Drops the orginal column from the df, then concatenates the new dataframe(s), axis=1 ensures column wise concatenation\n",
        "    df_encoded = pd.concat([df_encoded.drop(columns=[col]), encoded_df], axis=1)\n",
        "\n",
        "df_encoded.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "gd8Daoo9QIXb",
        "outputId": "b453f68b-472e-43da-8cd2-f532f2e6f4d6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  Gender_Male  Polyuria_Yes  Polydipsia_Yes  sudden weight loss_Yes  \\\n",
              "0   40          1.0           0.0             1.0                     0.0   \n",
              "1   58          1.0           0.0             0.0                     0.0   \n",
              "2   41          1.0           1.0             0.0                     0.0   \n",
              "3   45          1.0           0.0             0.0                     1.0   \n",
              "4   60          1.0           1.0             1.0                     1.0   \n",
              "\n",
              "   weakness_Yes  Polyphagia_Yes  Genital thrush_Yes  visual blurring_Yes  \\\n",
              "0           1.0             0.0                 0.0                  0.0   \n",
              "1           1.0             0.0                 0.0                  1.0   \n",
              "2           1.0             1.0                 0.0                  0.0   \n",
              "3           1.0             1.0                 1.0                  0.0   \n",
              "4           1.0             1.0                 0.0                  1.0   \n",
              "\n",
              "   Itching_Yes  Irritability_Yes  delayed healing_Yes  partial paresis_Yes  \\\n",
              "0          1.0               0.0                  1.0                  0.0   \n",
              "1          0.0               0.0                  0.0                  1.0   \n",
              "2          1.0               0.0                  1.0                  0.0   \n",
              "3          1.0               0.0                  1.0                  0.0   \n",
              "4          1.0               1.0                  1.0                  1.0   \n",
              "\n",
              "   muscle stiffness_Yes  Alopecia_Yes  Obesity_Yes  class_Positive  \n",
              "0                   1.0           1.0          1.0             1.0  \n",
              "1                   0.0           1.0          0.0             1.0  \n",
              "2                   1.0           1.0          0.0             1.0  \n",
              "3                   0.0           0.0          0.0             1.0  \n",
              "4                   1.0           1.0          1.0             1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-118183fa-dc2d-4081-9df2-567f939c40fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Polyuria_Yes</th>\n",
              "      <th>Polydipsia_Yes</th>\n",
              "      <th>sudden weight loss_Yes</th>\n",
              "      <th>weakness_Yes</th>\n",
              "      <th>Polyphagia_Yes</th>\n",
              "      <th>Genital thrush_Yes</th>\n",
              "      <th>visual blurring_Yes</th>\n",
              "      <th>Itching_Yes</th>\n",
              "      <th>Irritability_Yes</th>\n",
              "      <th>delayed healing_Yes</th>\n",
              "      <th>partial paresis_Yes</th>\n",
              "      <th>muscle stiffness_Yes</th>\n",
              "      <th>Alopecia_Yes</th>\n",
              "      <th>Obesity_Yes</th>\n",
              "      <th>class_Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-118183fa-dc2d-4081-9df2-567f939c40fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-118183fa-dc2d-4081-9df2-567f939c40fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-118183fa-dc2d-4081-9df2-567f939c40fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f723ec56-9e41-44fd-8c61-ad8525f221ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f723ec56-9e41-44fd-8c61-ad8525f221ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f723ec56-9e41-44fd-8c61-ad8525f221ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_encoded",
              "summary": "{\n  \"name\": \"df_encoded\",\n  \"rows\": 520,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 16,\n        \"max\": 90,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          79,\n          90,\n          33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender_Male\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4830612329047302,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polyuria_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5004666563981023,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polydipsia_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49777554684298253,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sudden weight loss_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49358940673958085,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weakness_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49292835255534573,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polyphagia_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4985193728834038,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Genital thrush_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.41671038750906086,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"visual blurring_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49777554684298253,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Itching_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5003000433665971,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Irritability_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4288920861017091,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delayed healing_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4988463049741518,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partial paresis_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49566073204006966,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"muscle stiffness_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.484589093558012,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alopecia_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4755742747103406,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Obesity_Yes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.37531667376029265,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_Positive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48697272374767114,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Double check the data types to ensure they are all numerical\n",
        "df_encoded.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "c-BBdXzTSr6r",
        "outputId": "f4c9bbd1-e2f6-40f8-9dc1-7dc52cc4df18"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                         int64\n",
              "Gender_Male               float64\n",
              "Polyuria_Yes              float64\n",
              "Polydipsia_Yes            float64\n",
              "sudden weight loss_Yes    float64\n",
              "weakness_Yes              float64\n",
              "Polyphagia_Yes            float64\n",
              "Genital thrush_Yes        float64\n",
              "visual blurring_Yes       float64\n",
              "Itching_Yes               float64\n",
              "Irritability_Yes          float64\n",
              "delayed healing_Yes       float64\n",
              "partial paresis_Yes       float64\n",
              "muscle stiffness_Yes      float64\n",
              "Alopecia_Yes              float64\n",
              "Obesity_Yes               float64\n",
              "class_Positive            float64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender_Male</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Polyuria_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Polydipsia_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sudden weight loss_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weakness_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Polyphagia_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Genital thrush_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>visual blurring_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Itching_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Irritability_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delayed healing_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>partial paresis_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>muscle stiffness_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alopecia_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Obesity_Yes</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class_Positive</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Data\n",
        "\n",
        "Now we want to split the data into test and training sets. Validation sets can be done too, but for this code we are just doing training and test sets."
      ],
      "metadata": {
        "id": "klSnvnl6S5UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Training set has 80 percent of the data, test has 20\n",
        "train_set, test_set = train_test_split(df_encoded, test_size=0.2)\n",
        "train_set = train_set.reset_index(drop=True)\n",
        "test_set = test_set.reset_index(drop=True)\n",
        "train_set.shape, test_set.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEbxleBnSz7d",
        "outputId": "f7fbe541-94b4-4484-d829-8aaedf00a1f9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((416, 17), (104, 17))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "import torch\n",
        "\n",
        "# Takes a pandas DF and converts it into a tuple of Tensors, containing the feature tensor and the label Tensor.\n",
        "def create_dataset(data: pd.DataFrame) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    features = torch.tensor(data.drop(columns=['class_Positive']).to_numpy(), dtype=torch.float)\n",
        "    labels = torch.tensor(data['class_Positive'].to_numpy(), dtype=torch.float)\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "EVlJmAfWUSUL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_train, labels_train = create_dataset(train_set)\n",
        "features_test, labels_test = create_dataset(test_set)\n",
        "features_train.shape, labels_train.shape, features_test.shape, labels_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm9ct4MyVD1D",
        "outputId": "00cb1e9c-4773-43cc-feab-4da7a4d92e94"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([416, 16]),\n",
              " torch.Size([416]),\n",
              " torch.Size([104, 16]),\n",
              " torch.Size([104]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unsqueeze the labels tensors so their shape is the same as the features tensor.\n",
        "# instead of [1,0,0,1,0 ...] its [[1],[0],[0],[1],[0], ...]\n",
        "labels_train = labels_train.unsqueeze(1)\n",
        "labels_test = labels_test.unsqueeze(1)\n",
        "labels_train.shape, labels_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W4OhjfMxilz",
        "outputId": "d64873bf-6596-4707-a85c-3068f6a2ce54"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([416, 1]), torch.Size([104, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model\n",
        "\n",
        "Now we set up the paramaters to train the Model.\n",
        "\n",
        "We create the actual class for the NN itself.\n",
        "\n",
        "We then Loop through epochs of training until the loss is low or the loop finishes."
      ],
      "metadata": {
        "id": "vMyPmZKYy3qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = features_train.shape[1]\n",
        "n_classes = 1\n",
        "hidden_channels = input_size"
      ],
      "metadata": {
        "id": "SRwWMG66yD2R"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F #for activation function\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "\n",
        "class NN(torch.nn.Module):\n",
        "    def __init__(self, input_size: int, n_classes: int, hidden_channels: int):\n",
        "        # inheret the super class\n",
        "        super().__init__()\n",
        "        # create 2 dense layers.\n",
        "        self.linear_layer_1 = torch.nn.Linear(input_size, hidden_channels)\n",
        "        self.linear_layer_2 = torch.nn.Linear(hidden_channels, n_classes)\n",
        "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
        "      #use the features to pass every instance through the first layer\n",
        "      x = F.relu(self.linear_layer_1(features))\n",
        "      # use the outputs of the first layer as the input of the second layer\n",
        "      x = (self.linear_layer_2(x))\n",
        "      # final layer(matrix of size [1, 1])\n",
        "      # it will return the final layer for every input. For ex:\n",
        "      # if training data has 1000 instances, shape will be [1000, 1]\n",
        "      return x"
      ],
      "metadata": {
        "id": "rxc9mu19ypTe"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "model = NN(input_size, n_classes, hidden_channels)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "for epoch in range(200):\n",
        "    # zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Calls forward method of NN and gets a tensor of predictions\n",
        "    pred = model(features_train)\n",
        "    # calculates the loss\n",
        "    loss = criterion(pred, labels_train)\n",
        "    # calculates the gradients w.r.t the bias and weight matrix(the learnable paramaters in this case)\n",
        "    loss.backward()\n",
        "    # updates the weights and bias using the adam optimizer\n",
        "    optimizer.step()\n",
        "    print(f'Epoch: {epoch},\\nTrain Loss: {loss.item()}\\n')\n",
        "    # Calculates how this epoch of the model works on the test set, for comparison purposes\n",
        "    with torch.no_grad():\n",
        "      pred_test = model(features_test)\n",
        "      loss_test = criterion(pred_test, labels_test)\n",
        "    print(f'Test Loss: {loss_test.item()}\\n')\n",
        "    # Incase our loss gets too small we break\n",
        "    if loss.item() < 0.1:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWC9OG4Cyu-h",
        "outputId": "aa42239f-7fa6-4cc9-b1b0-badfa2813cb4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0,\n",
            "Train Loss: 2.7306151390075684\n",
            "\n",
            "Test Loss: 1.90442955493927\n",
            "\n",
            "Epoch: 1,\n",
            "Train Loss: 1.9693628549575806\n",
            "\n",
            "Test Loss: 1.3277556896209717\n",
            "\n",
            "Epoch: 2,\n",
            "Train Loss: 1.368752121925354\n",
            "\n",
            "Test Loss: 0.9121145606040955\n",
            "\n",
            "Epoch: 3,\n",
            "Train Loss: 0.9317986369132996\n",
            "\n",
            "Test Loss: 0.7034115195274353\n",
            "\n",
            "Epoch: 4,\n",
            "Train Loss: 0.7043991088867188\n",
            "\n",
            "Test Loss: 0.6923841238021851\n",
            "\n",
            "Epoch: 5,\n",
            "Train Loss: 0.6789941787719727\n",
            "\n",
            "Test Loss: 0.7765915393829346\n",
            "\n",
            "Epoch: 6,\n",
            "Train Loss: 0.7529303431510925\n",
            "\n",
            "Test Loss: 0.8679068088531494\n",
            "\n",
            "Epoch: 7,\n",
            "Train Loss: 0.8382776975631714\n",
            "\n",
            "Test Loss: 0.9330994486808777\n",
            "\n",
            "Epoch: 8,\n",
            "Train Loss: 0.9000421762466431\n",
            "\n",
            "Test Loss: 0.9665456414222717\n",
            "\n",
            "Epoch: 9,\n",
            "Train Loss: 0.9320188164710999\n",
            "\n",
            "Test Loss: 0.9712031483650208\n",
            "\n",
            "Epoch: 10,\n",
            "Train Loss: 0.9365971088409424\n",
            "\n",
            "Test Loss: 0.9523171186447144\n",
            "\n",
            "Epoch: 11,\n",
            "Train Loss: 0.9188035726547241\n",
            "\n",
            "Test Loss: 0.9164340496063232\n",
            "\n",
            "Epoch: 12,\n",
            "Train Loss: 0.8848500847816467\n",
            "\n",
            "Test Loss: 0.8695341944694519\n",
            "\n",
            "Epoch: 13,\n",
            "Train Loss: 0.8405911326408386\n",
            "\n",
            "Test Loss: 0.8172935843467712\n",
            "\n",
            "Epoch: 14,\n",
            "Train Loss: 0.7914749383926392\n",
            "\n",
            "Test Loss: 0.765312135219574\n",
            "\n",
            "Epoch: 15,\n",
            "Train Loss: 0.7429500818252563\n",
            "\n",
            "Test Loss: 0.7188103795051575\n",
            "\n",
            "Epoch: 16,\n",
            "Train Loss: 0.7001124620437622\n",
            "\n",
            "Test Loss: 0.6821485757827759\n",
            "\n",
            "Epoch: 17,\n",
            "Train Loss: 0.6672009825706482\n",
            "\n",
            "Test Loss: 0.6580668687820435\n",
            "\n",
            "Epoch: 18,\n",
            "Train Loss: 0.6468461155891418\n",
            "\n",
            "Test Loss: 0.6470137238502502\n",
            "\n",
            "Epoch: 19,\n",
            "Train Loss: 0.639189600944519\n",
            "\n",
            "Test Loss: 0.6463664174079895\n",
            "\n",
            "Epoch: 20,\n",
            "Train Loss: 0.641291081905365\n",
            "\n",
            "Test Loss: 0.6501786708831787\n",
            "\n",
            "Epoch: 21,\n",
            "Train Loss: 0.6472688913345337\n",
            "\n",
            "Test Loss: 0.6546105742454529\n",
            "\n",
            "Epoch: 22,\n",
            "Train Loss: 0.653239905834198\n",
            "\n",
            "Test Loss: 0.6568151116371155\n",
            "\n",
            "Epoch: 23,\n",
            "Train Loss: 0.656122624874115\n",
            "\n",
            "Test Loss: 0.6538324952125549\n",
            "\n",
            "Epoch: 24,\n",
            "Train Loss: 0.6530005931854248\n",
            "\n",
            "Test Loss: 0.6455919742584229\n",
            "\n",
            "Epoch: 25,\n",
            "Train Loss: 0.6438847780227661\n",
            "\n",
            "Test Loss: 0.6338167190551758\n",
            "\n",
            "Epoch: 26,\n",
            "Train Loss: 0.6305986046791077\n",
            "\n",
            "Test Loss: 0.6213411092758179\n",
            "\n",
            "Epoch: 27,\n",
            "Train Loss: 0.6161270141601562\n",
            "\n",
            "Test Loss: 0.6112471222877502\n",
            "\n",
            "Epoch: 28,\n",
            "Train Loss: 0.6037387251853943\n",
            "\n",
            "Test Loss: 0.6058393716812134\n",
            "\n",
            "Epoch: 29,\n",
            "Train Loss: 0.5959503054618835\n",
            "\n",
            "Test Loss: 0.6056674718856812\n",
            "\n",
            "Epoch: 30,\n",
            "Train Loss: 0.5935431718826294\n",
            "\n",
            "Test Loss: 0.6089510917663574\n",
            "\n",
            "Epoch: 31,\n",
            "Train Loss: 0.5949769020080566\n",
            "\n",
            "Test Loss: 0.6121243834495544\n",
            "\n",
            "Epoch: 32,\n",
            "Train Loss: 0.596891462802887\n",
            "\n",
            "Test Loss: 0.6117976903915405\n",
            "\n",
            "Epoch: 33,\n",
            "Train Loss: 0.5960003137588501\n",
            "\n",
            "Test Loss: 0.606624960899353\n",
            "\n",
            "Epoch: 34,\n",
            "Train Loss: 0.5909335017204285\n",
            "\n",
            "Test Loss: 0.5975327491760254\n",
            "\n",
            "Epoch: 35,\n",
            "Train Loss: 0.5825009346008301\n",
            "\n",
            "Test Loss: 0.5867649912834167\n",
            "\n",
            "Epoch: 36,\n",
            "Train Loss: 0.5727866888046265\n",
            "\n",
            "Test Loss: 0.5767160654067993\n",
            "\n",
            "Epoch: 37,\n",
            "Train Loss: 0.5640131235122681\n",
            "\n",
            "Test Loss: 0.5689868927001953\n",
            "\n",
            "Epoch: 38,\n",
            "Train Loss: 0.5576070547103882\n",
            "\n",
            "Test Loss: 0.5638809204101562\n",
            "\n",
            "Epoch: 39,\n",
            "Train Loss: 0.5536881685256958\n",
            "\n",
            "Test Loss: 0.5605298280715942\n",
            "\n",
            "Epoch: 40,\n",
            "Train Loss: 0.5512332320213318\n",
            "\n",
            "Test Loss: 0.557433009147644\n",
            "\n",
            "Epoch: 41,\n",
            "Train Loss: 0.548658013343811\n",
            "\n",
            "Test Loss: 0.5533503293991089\n",
            "\n",
            "Epoch: 42,\n",
            "Train Loss: 0.5446761250495911\n",
            "\n",
            "Test Loss: 0.5477802753448486\n",
            "\n",
            "Epoch: 43,\n",
            "Train Loss: 0.5388144850730896\n",
            "\n",
            "Test Loss: 0.5410650968551636\n",
            "\n",
            "Epoch: 44,\n",
            "Train Loss: 0.5314826369285583\n",
            "\n",
            "Test Loss: 0.5340957045555115\n",
            "\n",
            "Epoch: 45,\n",
            "Train Loss: 0.5236656069755554\n",
            "\n",
            "Test Loss: 0.5278374552726746\n",
            "\n",
            "Epoch: 46,\n",
            "Train Loss: 0.516423225402832\n",
            "\n",
            "Test Loss: 0.5227383375167847\n",
            "\n",
            "Epoch: 47,\n",
            "Train Loss: 0.5103581547737122\n",
            "\n",
            "Test Loss: 0.5185261368751526\n",
            "\n",
            "Epoch: 48,\n",
            "Train Loss: 0.5053212642669678\n",
            "\n",
            "Test Loss: 0.514337420463562\n",
            "\n",
            "Epoch: 49,\n",
            "Train Loss: 0.5005348920822144\n",
            "\n",
            "Test Loss: 0.5092341303825378\n",
            "\n",
            "Epoch: 50,\n",
            "Train Loss: 0.4951149821281433\n",
            "\n",
            "Test Loss: 0.502754807472229\n",
            "\n",
            "Epoch: 51,\n",
            "Train Loss: 0.488596111536026\n",
            "\n",
            "Test Loss: 0.4951539635658264\n",
            "\n",
            "Epoch: 52,\n",
            "Train Loss: 0.4811881482601166\n",
            "\n",
            "Test Loss: 0.48719990253448486\n",
            "\n",
            "Epoch: 53,\n",
            "Train Loss: 0.4735827147960663\n",
            "\n",
            "Test Loss: 0.47970718145370483\n",
            "\n",
            "Epoch: 54,\n",
            "Train Loss: 0.4664973020553589\n",
            "\n",
            "Test Loss: 0.47307702898979187\n",
            "\n",
            "Epoch: 55,\n",
            "Train Loss: 0.4602314531803131\n",
            "\n",
            "Test Loss: 0.46710360050201416\n",
            "\n",
            "Epoch: 56,\n",
            "Train Loss: 0.4544873535633087\n",
            "\n",
            "Test Loss: 0.4611853361129761\n",
            "\n",
            "Epoch: 57,\n",
            "Train Loss: 0.44859805703163147\n",
            "\n",
            "Test Loss: 0.4548288583755493\n",
            "\n",
            "Epoch: 58,\n",
            "Train Loss: 0.4420478641986847\n",
            "\n",
            "Test Loss: 0.44803816080093384\n",
            "\n",
            "Epoch: 59,\n",
            "Train Loss: 0.43487030267715454\n",
            "\n",
            "Test Loss: 0.4412672221660614\n",
            "\n",
            "Epoch: 60,\n",
            "Train Loss: 0.42758414149284363\n",
            "\n",
            "Test Loss: 0.43499451875686646\n",
            "\n",
            "Epoch: 61,\n",
            "Train Loss: 0.42076289653778076\n",
            "\n",
            "Test Loss: 0.4292864501476288\n",
            "\n",
            "Epoch: 62,\n",
            "Train Loss: 0.414552241563797\n",
            "\n",
            "Test Loss: 0.42372989654541016\n",
            "\n",
            "Epoch: 63,\n",
            "Train Loss: 0.4086095094680786\n",
            "\n",
            "Test Loss: 0.4178083837032318\n",
            "\n",
            "Epoch: 64,\n",
            "Train Loss: 0.4024568200111389\n",
            "\n",
            "Test Loss: 0.4113726019859314\n",
            "\n",
            "Epoch: 65,\n",
            "Train Loss: 0.39594173431396484\n",
            "\n",
            "Test Loss: 0.40476030111312866\n",
            "\n",
            "Epoch: 66,\n",
            "Train Loss: 0.3893612027168274\n",
            "\n",
            "Test Loss: 0.39847660064697266\n",
            "\n",
            "Epoch: 67,\n",
            "Train Loss: 0.38315317034721375\n",
            "\n",
            "Test Loss: 0.3927437663078308\n",
            "\n",
            "Epoch: 68,\n",
            "Train Loss: 0.3774636685848236\n",
            "\n",
            "Test Loss: 0.38734933733940125\n",
            "\n",
            "Epoch: 69,\n",
            "Train Loss: 0.3720148205757141\n",
            "\n",
            "Test Loss: 0.38195154070854187\n",
            "\n",
            "Epoch: 70,\n",
            "Train Loss: 0.3664303123950958\n",
            "\n",
            "Test Loss: 0.3764968514442444\n",
            "\n",
            "Epoch: 71,\n",
            "Train Loss: 0.3606632649898529\n",
            "\n",
            "Test Loss: 0.3712518811225891\n",
            "\n",
            "Epoch: 72,\n",
            "Train Loss: 0.35502374172210693\n",
            "\n",
            "Test Loss: 0.36643555760383606\n",
            "\n",
            "Epoch: 73,\n",
            "Train Loss: 0.34979695081710815\n",
            "\n",
            "Test Loss: 0.36191898584365845\n",
            "\n",
            "Epoch: 74,\n",
            "Train Loss: 0.3449222147464752\n",
            "\n",
            "Test Loss: 0.35736605525016785\n",
            "\n",
            "Epoch: 75,\n",
            "Train Loss: 0.3401094973087311\n",
            "\n",
            "Test Loss: 0.3526304066181183\n",
            "\n",
            "Epoch: 76,\n",
            "Train Loss: 0.33522048592567444\n",
            "\n",
            "Test Loss: 0.34790948033332825\n",
            "\n",
            "Epoch: 77,\n",
            "Train Loss: 0.33042412996292114\n",
            "\n",
            "Test Loss: 0.3434847593307495\n",
            "\n",
            "Epoch: 78,\n",
            "Train Loss: 0.32594773173332214\n",
            "\n",
            "Test Loss: 0.33950409293174744\n",
            "\n",
            "Epoch: 79,\n",
            "Train Loss: 0.32184773683547974\n",
            "\n",
            "Test Loss: 0.335662841796875\n",
            "\n",
            "Epoch: 80,\n",
            "Train Loss: 0.317796528339386\n",
            "\n",
            "Test Loss: 0.3318476378917694\n",
            "\n",
            "Epoch: 81,\n",
            "Train Loss: 0.3136752247810364\n",
            "\n",
            "Test Loss: 0.3282562494277954\n",
            "\n",
            "Epoch: 82,\n",
            "Train Loss: 0.30971699953079224\n",
            "\n",
            "Test Loss: 0.32498660683631897\n",
            "\n",
            "Epoch: 83,\n",
            "Train Loss: 0.306082546710968\n",
            "\n",
            "Test Loss: 0.32185009121894836\n",
            "\n",
            "Epoch: 84,\n",
            "Train Loss: 0.30264008045196533\n",
            "\n",
            "Test Loss: 0.3186243176460266\n",
            "\n",
            "Epoch: 85,\n",
            "Train Loss: 0.2991970181465149\n",
            "\n",
            "Test Loss: 0.31538787484169006\n",
            "\n",
            "Epoch: 86,\n",
            "Train Loss: 0.2958161532878876\n",
            "\n",
            "Test Loss: 0.3122294843196869\n",
            "\n",
            "Epoch: 87,\n",
            "Train Loss: 0.29259344935417175\n",
            "\n",
            "Test Loss: 0.3089580833911896\n",
            "\n",
            "Epoch: 88,\n",
            "Train Loss: 0.28968408703804016\n",
            "\n",
            "Test Loss: 0.30600714683532715\n",
            "\n",
            "Epoch: 89,\n",
            "Train Loss: 0.28670957684516907\n",
            "\n",
            "Test Loss: 0.3033609092235565\n",
            "\n",
            "Epoch: 90,\n",
            "Train Loss: 0.28367772698402405\n",
            "\n",
            "Test Loss: 0.3011073172092438\n",
            "\n",
            "Epoch: 91,\n",
            "Train Loss: 0.2808550000190735\n",
            "\n",
            "Test Loss: 0.2988385558128357\n",
            "\n",
            "Epoch: 92,\n",
            "Train Loss: 0.27823489904403687\n",
            "\n",
            "Test Loss: 0.2962084710597992\n",
            "\n",
            "Epoch: 93,\n",
            "Train Loss: 0.2755703330039978\n",
            "\n",
            "Test Loss: 0.29332584142684937\n",
            "\n",
            "Epoch: 94,\n",
            "Train Loss: 0.272920697927475\n",
            "\n",
            "Test Loss: 0.290568083524704\n",
            "\n",
            "Epoch: 95,\n",
            "Train Loss: 0.270476758480072\n",
            "\n",
            "Test Loss: 0.28819993138313293\n",
            "\n",
            "Epoch: 96,\n",
            "Train Loss: 0.2681169807910919\n",
            "\n",
            "Test Loss: 0.28617480397224426\n",
            "\n",
            "Epoch: 97,\n",
            "Train Loss: 0.2657296061515808\n",
            "\n",
            "Test Loss: 0.2843571901321411\n",
            "\n",
            "Epoch: 98,\n",
            "Train Loss: 0.2634750306606293\n",
            "\n",
            "Test Loss: 0.2825756072998047\n",
            "\n",
            "Epoch: 99,\n",
            "Train Loss: 0.2613198459148407\n",
            "\n",
            "Test Loss: 0.2806928753852844\n",
            "\n",
            "Epoch: 100,\n",
            "Train Loss: 0.25921323895454407\n",
            "\n",
            "Test Loss: 0.2786961793899536\n",
            "\n",
            "Epoch: 101,\n",
            "Train Loss: 0.25714606046676636\n",
            "\n",
            "Test Loss: 0.2767094373703003\n",
            "\n",
            "Epoch: 102,\n",
            "Train Loss: 0.255153626203537\n",
            "\n",
            "Test Loss: 0.2748534381389618\n",
            "\n",
            "Epoch: 103,\n",
            "Train Loss: 0.2532426118850708\n",
            "\n",
            "Test Loss: 0.27318456768989563\n",
            "\n",
            "Epoch: 104,\n",
            "Train Loss: 0.2513810396194458\n",
            "\n",
            "Test Loss: 0.2717020809650421\n",
            "\n",
            "Epoch: 105,\n",
            "Train Loss: 0.24955520033836365\n",
            "\n",
            "Test Loss: 0.2703627943992615\n",
            "\n",
            "Epoch: 106,\n",
            "Train Loss: 0.24778707325458527\n",
            "\n",
            "Test Loss: 0.2690819203853607\n",
            "\n",
            "Epoch: 107,\n",
            "Train Loss: 0.24609501659870148\n",
            "\n",
            "Test Loss: 0.2676723003387451\n",
            "\n",
            "Epoch: 108,\n",
            "Train Loss: 0.24443601071834564\n",
            "\n",
            "Test Loss: 0.2661469578742981\n",
            "\n",
            "Epoch: 109,\n",
            "Train Loss: 0.24280712008476257\n",
            "\n",
            "Test Loss: 0.2646470367908478\n",
            "\n",
            "Epoch: 110,\n",
            "Train Loss: 0.2412470281124115\n",
            "\n",
            "Test Loss: 0.26334211230278015\n",
            "\n",
            "Epoch: 111,\n",
            "Train Loss: 0.2397300899028778\n",
            "\n",
            "Test Loss: 0.2622356116771698\n",
            "\n",
            "Epoch: 112,\n",
            "Train Loss: 0.23823142051696777\n",
            "\n",
            "Test Loss: 0.261300265789032\n",
            "\n",
            "Epoch: 113,\n",
            "Train Loss: 0.23679327964782715\n",
            "\n",
            "Test Loss: 0.2602897882461548\n",
            "\n",
            "Epoch: 114,\n",
            "Train Loss: 0.23539792001247406\n",
            "\n",
            "Test Loss: 0.2591311037540436\n",
            "\n",
            "Epoch: 115,\n",
            "Train Loss: 0.23401802778244019\n",
            "\n",
            "Test Loss: 0.25776827335357666\n",
            "\n",
            "Epoch: 116,\n",
            "Train Loss: 0.2326754927635193\n",
            "\n",
            "Test Loss: 0.2564443349838257\n",
            "\n",
            "Epoch: 117,\n",
            "Train Loss: 0.23138324916362762\n",
            "\n",
            "Test Loss: 0.2553405165672302\n",
            "\n",
            "Epoch: 118,\n",
            "Train Loss: 0.23011234402656555\n",
            "\n",
            "Test Loss: 0.2544190287590027\n",
            "\n",
            "Epoch: 119,\n",
            "Train Loss: 0.2288685142993927\n",
            "\n",
            "Test Loss: 0.25355857610702515\n",
            "\n",
            "Epoch: 120,\n",
            "Train Loss: 0.22766484320163727\n",
            "\n",
            "Test Loss: 0.2526158392429352\n",
            "\n",
            "Epoch: 121,\n",
            "Train Loss: 0.22649239003658295\n",
            "\n",
            "Test Loss: 0.2515279948711395\n",
            "\n",
            "Epoch: 122,\n",
            "Train Loss: 0.22533954679965973\n",
            "\n",
            "Test Loss: 0.2503601312637329\n",
            "\n",
            "Epoch: 123,\n",
            "Train Loss: 0.22421357035636902\n",
            "\n",
            "Test Loss: 0.24924257397651672\n",
            "\n",
            "Epoch: 124,\n",
            "Train Loss: 0.22312071919441223\n",
            "\n",
            "Test Loss: 0.2482740730047226\n",
            "\n",
            "Epoch: 125,\n",
            "Train Loss: 0.22205199301242828\n",
            "\n",
            "Test Loss: 0.24746809899806976\n",
            "\n",
            "Epoch: 126,\n",
            "Train Loss: 0.22100219130516052\n",
            "\n",
            "Test Loss: 0.24675917625427246\n",
            "\n",
            "Epoch: 127,\n",
            "Train Loss: 0.21997769176959991\n",
            "\n",
            "Test Loss: 0.24603785574436188\n",
            "\n",
            "Epoch: 128,\n",
            "Train Loss: 0.21897974610328674\n",
            "\n",
            "Test Loss: 0.24522201716899872\n",
            "\n",
            "Epoch: 129,\n",
            "Train Loss: 0.21800096333026886\n",
            "\n",
            "Test Loss: 0.24432002007961273\n",
            "\n",
            "Epoch: 130,\n",
            "Train Loss: 0.21704056859016418\n",
            "\n",
            "Test Loss: 0.24341759085655212\n",
            "\n",
            "Epoch: 131,\n",
            "Train Loss: 0.2161034494638443\n",
            "\n",
            "Test Loss: 0.2426060289144516\n",
            "\n",
            "Epoch: 132,\n",
            "Train Loss: 0.21518732607364655\n",
            "\n",
            "Test Loss: 0.2419242560863495\n",
            "\n",
            "Epoch: 133,\n",
            "Train Loss: 0.21428745985031128\n",
            "\n",
            "Test Loss: 0.24133537709712982\n",
            "\n",
            "Epoch: 134,\n",
            "Train Loss: 0.21340586245059967\n",
            "\n",
            "Test Loss: 0.24075530469417572\n",
            "\n",
            "Epoch: 135,\n",
            "Train Loss: 0.2125461846590042\n",
            "\n",
            "Test Loss: 0.24014391005039215\n",
            "\n",
            "Epoch: 136,\n",
            "Train Loss: 0.21170450747013092\n",
            "\n",
            "Test Loss: 0.23946765065193176\n",
            "\n",
            "Epoch: 137,\n",
            "Train Loss: 0.21087795495986938\n",
            "\n",
            "Test Loss: 0.23875877261161804\n",
            "\n",
            "Epoch: 138,\n",
            "Train Loss: 0.2100677639245987\n",
            "\n",
            "Test Loss: 0.23808428645133972\n",
            "\n",
            "Epoch: 139,\n",
            "Train Loss: 0.20927463471889496\n",
            "\n",
            "Test Loss: 0.23749375343322754\n",
            "\n",
            "Epoch: 140,\n",
            "Train Loss: 0.20849670469760895\n",
            "\n",
            "Test Loss: 0.23699787259101868\n",
            "\n",
            "Epoch: 141,\n",
            "Train Loss: 0.2077329307794571\n",
            "\n",
            "Test Loss: 0.2365420013666153\n",
            "\n",
            "Epoch: 142,\n",
            "Train Loss: 0.206984743475914\n",
            "\n",
            "Test Loss: 0.23605778813362122\n",
            "\n",
            "Epoch: 143,\n",
            "Train Loss: 0.20625101029872894\n",
            "\n",
            "Test Loss: 0.23552490770816803\n",
            "\n",
            "Epoch: 144,\n",
            "Train Loss: 0.20554104447364807\n",
            "\n",
            "Test Loss: 0.2352602332830429\n",
            "\n",
            "Epoch: 145,\n",
            "Train Loss: 0.20483660697937012\n",
            "\n",
            "Test Loss: 0.23510822653770447\n",
            "\n",
            "Epoch: 146,\n",
            "Train Loss: 0.2041596621274948\n",
            "\n",
            "Test Loss: 0.23452292382717133\n",
            "\n",
            "Epoch: 147,\n",
            "Train Loss: 0.20347732305526733\n",
            "\n",
            "Test Loss: 0.23398913443088531\n",
            "\n",
            "Epoch: 148,\n",
            "Train Loss: 0.20281654596328735\n",
            "\n",
            "Test Loss: 0.23359976708889008\n",
            "\n",
            "Epoch: 149,\n",
            "Train Loss: 0.2021649032831192\n",
            "\n",
            "Test Loss: 0.23336230218410492\n",
            "\n",
            "Epoch: 150,\n",
            "Train Loss: 0.20152023434638977\n",
            "\n",
            "Test Loss: 0.233192577958107\n",
            "\n",
            "Epoch: 151,\n",
            "Train Loss: 0.2008880078792572\n",
            "\n",
            "Test Loss: 0.23298241198062897\n",
            "\n",
            "Epoch: 152,\n",
            "Train Loss: 0.20027431845664978\n",
            "\n",
            "Test Loss: 0.2323572039604187\n",
            "\n",
            "Epoch: 153,\n",
            "Train Loss: 0.19965918362140656\n",
            "\n",
            "Test Loss: 0.23193462193012238\n",
            "\n",
            "Epoch: 154,\n",
            "Train Loss: 0.19906722009181976\n",
            "\n",
            "Test Loss: 0.23179766535758972\n",
            "\n",
            "Epoch: 155,\n",
            "Train Loss: 0.1984720528125763\n",
            "\n",
            "Test Loss: 0.23187074065208435\n",
            "\n",
            "Epoch: 156,\n",
            "Train Loss: 0.19791467487812042\n",
            "\n",
            "Test Loss: 0.23156271874904633\n",
            "\n",
            "Epoch: 157,\n",
            "Train Loss: 0.19734741747379303\n",
            "\n",
            "Test Loss: 0.23096631467342377\n",
            "\n",
            "Epoch: 158,\n",
            "Train Loss: 0.19678090512752533\n",
            "\n",
            "Test Loss: 0.23041297495365143\n",
            "\n",
            "Epoch: 159,\n",
            "Train Loss: 0.19625785946846008\n",
            "\n",
            "Test Loss: 0.2303837239742279\n",
            "\n",
            "Epoch: 160,\n",
            "Train Loss: 0.1956966072320938\n",
            "\n",
            "Test Loss: 0.23072046041488647\n",
            "\n",
            "Epoch: 161,\n",
            "Train Loss: 0.19518516957759857\n",
            "\n",
            "Test Loss: 0.2306036353111267\n",
            "\n",
            "Epoch: 162,\n",
            "Train Loss: 0.19467313587665558\n",
            "\n",
            "Test Loss: 0.22995556890964508\n",
            "\n",
            "Epoch: 163,\n",
            "Train Loss: 0.19413068890571594\n",
            "\n",
            "Test Loss: 0.2292052060365677\n",
            "\n",
            "Epoch: 164,\n",
            "Train Loss: 0.19365336000919342\n",
            "\n",
            "Test Loss: 0.22901786863803864\n",
            "\n",
            "Epoch: 165,\n",
            "Train Loss: 0.19315393269062042\n",
            "\n",
            "Test Loss: 0.22930866479873657\n",
            "\n",
            "Epoch: 166,\n",
            "Train Loss: 0.1926407516002655\n",
            "\n",
            "Test Loss: 0.2293524444103241\n",
            "\n",
            "Epoch: 167,\n",
            "Train Loss: 0.19217635691165924\n",
            "\n",
            "Test Loss: 0.22889766097068787\n",
            "\n",
            "Epoch: 168,\n",
            "Train Loss: 0.19168700277805328\n",
            "\n",
            "Test Loss: 0.22850832343101501\n",
            "\n",
            "Epoch: 169,\n",
            "Train Loss: 0.19122594594955444\n",
            "\n",
            "Test Loss: 0.2283051609992981\n",
            "\n",
            "Epoch: 170,\n",
            "Train Loss: 0.19076824188232422\n",
            "\n",
            "Test Loss: 0.22827185690402985\n",
            "\n",
            "Epoch: 171,\n",
            "Train Loss: 0.1903139054775238\n",
            "\n",
            "Test Loss: 0.22826717793941498\n",
            "\n",
            "Epoch: 172,\n",
            "Train Loss: 0.18987372517585754\n",
            "\n",
            "Test Loss: 0.2278301864862442\n",
            "\n",
            "Epoch: 173,\n",
            "Train Loss: 0.1894323229789734\n",
            "\n",
            "Test Loss: 0.22751833498477936\n",
            "\n",
            "Epoch: 174,\n",
            "Train Loss: 0.18900473415851593\n",
            "\n",
            "Test Loss: 0.227423757314682\n",
            "\n",
            "Epoch: 175,\n",
            "Train Loss: 0.1885768473148346\n",
            "\n",
            "Test Loss: 0.2274649292230606\n",
            "\n",
            "Epoch: 176,\n",
            "Train Loss: 0.18815670907497406\n",
            "\n",
            "Test Loss: 0.22716093063354492\n",
            "\n",
            "Epoch: 177,\n",
            "Train Loss: 0.1877455711364746\n",
            "\n",
            "Test Loss: 0.2269485592842102\n",
            "\n",
            "Epoch: 178,\n",
            "Train Loss: 0.18734097480773926\n",
            "\n",
            "Test Loss: 0.22685378789901733\n",
            "\n",
            "Epoch: 179,\n",
            "Train Loss: 0.18694041669368744\n",
            "\n",
            "Test Loss: 0.2268071323633194\n",
            "\n",
            "Epoch: 180,\n",
            "Train Loss: 0.1865490823984146\n",
            "\n",
            "Test Loss: 0.2264029085636139\n",
            "\n",
            "Epoch: 181,\n",
            "Train Loss: 0.18616102635860443\n",
            "\n",
            "Test Loss: 0.22617611289024353\n",
            "\n",
            "Epoch: 182,\n",
            "Train Loss: 0.18578065931797028\n",
            "\n",
            "Test Loss: 0.22615550458431244\n",
            "\n",
            "Epoch: 183,\n",
            "Train Loss: 0.18540024757385254\n",
            "\n",
            "Test Loss: 0.22619979083538055\n",
            "\n",
            "Epoch: 184,\n",
            "Train Loss: 0.18503254652023315\n",
            "\n",
            "Test Loss: 0.2258121818304062\n",
            "\n",
            "Epoch: 185,\n",
            "Train Loss: 0.18466350436210632\n",
            "\n",
            "Test Loss: 0.22552067041397095\n",
            "\n",
            "Epoch: 186,\n",
            "Train Loss: 0.18430623412132263\n",
            "\n",
            "Test Loss: 0.22542007267475128\n",
            "\n",
            "Epoch: 187,\n",
            "Train Loss: 0.1839495301246643\n",
            "\n",
            "Test Loss: 0.22543789446353912\n",
            "\n",
            "Epoch: 188,\n",
            "Train Loss: 0.1835981160402298\n",
            "\n",
            "Test Loss: 0.2254033386707306\n",
            "\n",
            "Epoch: 189,\n",
            "Train Loss: 0.1832549273967743\n",
            "\n",
            "Test Loss: 0.22491352260112762\n",
            "\n",
            "Epoch: 190,\n",
            "Train Loss: 0.18291427195072174\n",
            "\n",
            "Test Loss: 0.22461499273777008\n",
            "\n",
            "Epoch: 191,\n",
            "Train Loss: 0.18258428573608398\n",
            "\n",
            "Test Loss: 0.22460603713989258\n",
            "\n",
            "Epoch: 192,\n",
            "Train Loss: 0.1822483241558075\n",
            "\n",
            "Test Loss: 0.22472620010375977\n",
            "\n",
            "Epoch: 193,\n",
            "Train Loss: 0.18192245066165924\n",
            "\n",
            "Test Loss: 0.22469529509544373\n",
            "\n",
            "Epoch: 194,\n",
            "Train Loss: 0.18160584568977356\n",
            "\n",
            "Test Loss: 0.22410748898983002\n",
            "\n",
            "Epoch: 195,\n",
            "Train Loss: 0.1812857836484909\n",
            "\n",
            "Test Loss: 0.2237243801355362\n",
            "\n",
            "Epoch: 196,\n",
            "Train Loss: 0.18098363280296326\n",
            "\n",
            "Test Loss: 0.223717600107193\n",
            "\n",
            "Epoch: 197,\n",
            "Train Loss: 0.18066859245300293\n",
            "\n",
            "Test Loss: 0.22391480207443237\n",
            "\n",
            "Epoch: 198,\n",
            "Train Loss: 0.180363267660141\n",
            "\n",
            "Test Loss: 0.22395512461662292\n",
            "\n",
            "Epoch: 199,\n",
            "Train Loss: 0.18007157742977142\n",
            "\n",
            "Test Loss: 0.22364817559719086\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate ROC AUC and F1 score\n",
        "\n",
        "We calculate the ROC AUC and f1 score to see how well our model works on unseen data."
      ],
      "metadata": {
        "id": "LtUK8oqsk4Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the predictions on the test set in a new variable\n",
        "with torch.no_grad():\n",
        "  test_pred = model(features_test)\n",
        "  loss = criterion(test_pred, labels_test)\n",
        "  print(f'Test Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3xVf4I407iK",
        "outputId": "04474c0b-48b3-41af-99f5-e7ba02b59dcb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.22364817559719086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "\n",
        "# Convert the predictions  to numpy arrays then apply the sigmoid function to them\n",
        "pred_probs = torch.sigmoid(test_pred).cpu().numpy()\n",
        "\n",
        "#Probablility > 0.5 = classify as positive\n",
        "pred_labels = (pred_probs > 0.5).astype(int)\n",
        "\n",
        "# Convert the labels to numpy arrays\n",
        "labels_test_np = labels_test.cpu().numpy()\n",
        "\n",
        "# Calculate the ROC Area Under Curve score\n",
        "roc_auc = roc_auc_score(labels_test_np, pred_probs)\n",
        "print(f'ROC-AUC Score: {roc_auc}')\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(labels_test_np, pred_labels)\n",
        "print(f'F1 Score: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCGxEohX0yXM",
        "outputId": "bf75ae07-fd07-4a9e-8d78-f11a1f0cd6da"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9566395663956639\n",
            "F1 Score: 0.9105691056910569\n"
          ]
        }
      ]
    }
  ]
}